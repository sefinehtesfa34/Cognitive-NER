{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCYsy9yxuTbC",
        "outputId": "95ee691d-fb5f-4f98-a545-3928534568d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.30.1\n"
          ]
        }
      ],
      "source": [
        "# !pip install transformers datasets torch flask flask-cors  scikit-learn seqeval\n",
        "# !pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "id": "pKbuDBspjob6",
        "outputId": "8446c0cc-52e9-4d77-f01d-1af97efc344d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:1486: FutureWarning: The repository for conll2003 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/conll2003\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-1-2c02ce35719c>:42: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = load_metric(\"seqeval\")\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for seqeval contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/seqeval/seqeval.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2634' max='2634' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2634/2634 18:00, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.244000</td>\n",
              "      <td>0.071270</td>\n",
              "      <td>0.906956</td>\n",
              "      <td>0.919091</td>\n",
              "      <td>0.912983</td>\n",
              "      <td>0.978981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.051000</td>\n",
              "      <td>0.063794</td>\n",
              "      <td>0.929798</td>\n",
              "      <td>0.933639</td>\n",
              "      <td>0.931714</td>\n",
              "      <td>0.983768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.028000</td>\n",
              "      <td>0.059403</td>\n",
              "      <td>0.936998</td>\n",
              "      <td>0.942888</td>\n",
              "      <td>0.939934</td>\n",
              "      <td>0.985212</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://172.28.0.12:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import BertTokenizerFast, BertForTokenClassification, Trainer, TrainingArguments, DataCollatorForTokenClassification\n",
        "from datasets import load_dataset, load_metric\n",
        "import numpy as np\n",
        "from flask import Flask, request, jsonify\n",
        "from flask_cors import CORS\n",
        "\n",
        "# Load dataset\n",
        "dataset = load_dataset(\"conll2003\")\n",
        "label_list = dataset['train'].features['ner_tags'].feature.names\n",
        "\n",
        "# Initialize tokenizer and model\n",
        "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-cased\")\n",
        "model = BertForTokenClassification.from_pretrained(\"bert-base-cased\", num_labels=len(label_list))\n",
        "\n",
        "# Define label_all_tokens\n",
        "label_all_tokens = True\n",
        "\n",
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(examples['tokens'], truncation=True, is_split_into_words=True, padding='max_length', max_length=128)\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples[f'ner_tags']):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(label[word_idx])\n",
        "            else:\n",
        "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
        "            previous_word_idx = word_idx\n",
        "        labels.append(label_ids)\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs\n",
        "\n",
        "# Tokenize and align labels for train and validation sets\n",
        "tokenized_datasets = dataset.map(tokenize_and_align_labels, batched=True)\n",
        "\n",
        "# Load metric\n",
        "metric = load_metric(\"seqeval\")\n",
        "\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    true_predictions = [\n",
        "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "    return {\n",
        "        \"precision\": results[\"overall_precision\"],\n",
        "        \"recall\": results[\"overall_recall\"],\n",
        "        \"f1\": results[\"overall_f1\"],\n",
        "        \"accuracy\": results[\"overall_accuracy\"],\n",
        "    }\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "\n",
        "# Data collator for padding\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
        "\n",
        "# Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Train model\n",
        "trainer.train()\n",
        "\n",
        "# Save model\n",
        "trainer.save_model(\"ner_model\")\n",
        "\n",
        "# Initialize Flask app\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "\n",
        "@app.route('/extract_entities', methods=['POST'])\n",
        "def extract_entities():\n",
        "    data = request.get_json()\n",
        "    text = data['text']\n",
        "    tokens = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(text)))\n",
        "    inputs = tokenizer.encode(text, return_tensors=\"pt\")\n",
        "    outputs = model(inputs).logits\n",
        "    predictions = torch.argmax(outputs, dim=2)\n",
        "    entities = []\n",
        "    for token, label_id in zip(tokens, predictions[0].tolist()):\n",
        "        entities.append({\"word\": token, \"entity\": label_list[label_id]})\n",
        "    return jsonify(entities)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(host='0.0.0.0', port=5000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import requests \n",
        "response = requests.post(url = 'http://127.0.0.1:5000/extract_entities', json = {\"text\":\"Which country is highly speceializing in cognitive science and mind building?\"})\n",
        "response.status_code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'entity': 'O', 'word': '[CLS]'},\n",
              " {'entity': 'O', 'word': 'Which'},\n",
              " {'entity': 'O', 'word': 'country'},\n",
              " {'entity': 'O', 'word': 'is'},\n",
              " {'entity': 'O', 'word': 'highly'},\n",
              " {'entity': 'O', 'word': 's'},\n",
              " {'entity': 'O', 'word': '##pec'},\n",
              " {'entity': 'O', 'word': '##ei'},\n",
              " {'entity': 'O', 'word': '##ali'},\n",
              " {'entity': 'O', 'word': '##zing'},\n",
              " {'entity': 'O', 'word': 'in'},\n",
              " {'entity': 'O', 'word': 'cognitive'},\n",
              " {'entity': 'O', 'word': 'science'},\n",
              " {'entity': 'O', 'word': 'and'},\n",
              " {'entity': 'O', 'word': 'mind'},\n",
              " {'entity': 'O', 'word': 'building'},\n",
              " {'entity': 'O', 'word': '?'},\n",
              " {'entity': 'O', 'word': '[SEP]'}]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
